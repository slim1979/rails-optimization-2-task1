# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику:  
Я сформировал несколько файлов - от 10000 до 50000 строк из целевого файла с шагом 10000 строк и еще один файл со 100_000 строк.  
Цель - выявить асимптотику при увеличении объема.  
Результаты оказались интересными - запуск этих файлов дал такие результаты:  
    
    кол-во  время  
    10000	2,416479333
    20000	13,597099
    30000	30,022937
    40000	52,39150967
    50000	81,632466 
    100000  323,161269
    
Я построил график в excel, он был очень похож на линейный рост.  
Вывел формулу( надо сказать, не сам :) ), чтобы соотнести полученные результаты с общим объемом.  
Наилучшим образом подошла кубическая регрессия. Формула:    
y=0.00000000000003819201x3+0.00000002578006725116x2+0.00030694971755940159x+−3.68561302814850932918  
В том же excel примерно прикинул время выполнения общего объема данных исходя из 3_650_000 строк:  

    2 201 739,27    секунд
    36695,65452	минут
    611,594242	часов
    25,48309342	дней
    
Технически, дождаться можно) Но я попробую войти в бюджет.
Я решил начать работать с файлом в 20_000 строк. Он оптимальный по количеству и времени. Задача минимум - довести время исполнения до 1 секунды. Оттуда будет видно.    
  

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста в фидбек-лупе позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`:  
Я написал тест, который просто замерял время выполнения метода.  
Тест довольно прост, но позволяет динамически изменять объем файла, что удобно при изменении времени обработки файла.



## Вникаем в детали системы, чтобы найти главные точки роста
Для начала я решил проверить программу всеми доступными профайлерами, чтобы сформировать объективную картину.  
Я использовал файл из 20000 строк из целевого файла и приступил к профилированию.  
Профилировал, профилировал и напрофилировал следующее:  
Первый профайлер - ruby-prof.

    Measure Mode: wall_time
    Thread ID: 19318200
    Fiber ID: 25078840
    Total: 20.383624
    Sort by: self_time
    
     %self      total      self      wait     child     calls  name           
     94.78     19.320    19.320     0.000     0.000     3069   Array#select                   
      3.04     20.314     0.620     0.000    19.693    20010  *Array#each                     



второй - ruby-prof-graph
здесь я получил чуть более развернутую информацию о callers и callees

    %TOTAL	%SELF	TOTAL	SELF	WAIT	CHILD	CALLS	NAME	LINE
    100.00%	0.00%	21.27	0.00	0.00	21.27	1	[global]#	10
     	 	21.27	0.00	0.00	21.27	1/1	Object#work	10
     	 	0.00	0.00	0.00	0.00	1/2	<Object::Object>#[]	10
     	 	21.27	0.00	0.00	21.27	1/1	[global]#	10
    100.00%	0.00%	21.27	0.00	0.00	21.27	1	Object#work	46
     	 	20.86	0.28	0.00	20.58	3/20010	Array#each

этот профайлер так же определил точку роста - в методе #work.
на этом можно было бы и остановиться, но я решил попробовать другие профайлеры дял сравнения.
Вот какие проблемы удалось найти и решить

### Ваша находка №1
Я обнаружил, что данные подставлялись в метод #each в неоптимальном виде и решил перед итерацией сгруппировать данные по user_id.  
Группировка резко сократила время исполнения файла.  

    Файл из 20_000 строк обрабатывался теперь за 0.73 секунд.
    
В результате я переключился на работу с объемом в 100_000 строк, который теперь обрабатывался за 6 секунд.  

Профилирование показало следующее:  
    
    RubyProf::FlatPrinter
    
    %self      total      self      wait     child     calls  name                           location
     75.10      7.993     6.255     0.000     1.739   100011  *Array#each                     
      5.10      0.425     0.425     0.000     0.000   200001   String#split                   
      4.40      0.970     0.367     0.000     0.604   168896   Array#map                      
      3.22      0.510     0.269     0.000     0.242    84645   <Class::Date>#parse            
      1.88      0.287     0.156     0.000     0.130    84646   Object#parse_session

    RubyProf::GraphHtmlPrinter
    
    100.00%	0.01%	0.63	0.00	0.00	0.63	1	[global]#	10
     	 	0.63	0.00	0.00	0.63	1/1	Object#work	10
     	 	0.00	0.00	0.00	0.00	1/1	<Object::Object>#[]	10
     	 	0.63	0.00	0.00	0.63	1/1	[global]#	10
    99.99%	0.02%	0.63	0.00	0.00	0.63	1	Object#work	46
     	 	0.38	0.11	0.00	0.26	3/13265	Array#each	68
     	 	0.21	0.00	0.00	0.21	7/7	Object#collect_stats_from_users	127
     	 	0.02	0.01	0.00	0.01	1/1	JSON::Ext::Generator::GeneratorMethods::Hash#to_json	161
     	 	0.01	0.01	0.00	0.00	2/22310	Array#map	104
     	 	0.01	0.01	0.00	0.00	1/26509	String#split	50
     	 	0.01	0.00	0.00	0.01	1/1	Enumerable#group_by	114
     	 	0.00	0.00	0.00	0.00	1/4057	Array#sort	104
     	 	0.00	0.00	0.00	0.00	1/1	Array#uniq	104
     	 	0.00	0.00	0.00	0.00	1/1	<Class::IO>#write	161
     	 	0.00	0.00	0.00	0.00	1/1	<Class::IO>#read	50
     	 	0.00	0.00	0.00	0.00	2/2	Kernel#puts	47
     	 	0.00	0.00	0.00	0.00	1/2029	Array#join	104
     	 	0.00	0.00	0.00	0.00	3/2031	Array#count	91
     	 	0.01	0.01	0.00	0.00	1/13265	Enumerable#group_by	
     	 	0.18	0.18	0.00	0.00	13254/13265	Enumerable#all?	
     	 	0.21	0.04	0.00	0.16	7/13265	Object#collect_stats_from_users	39
     	 	0.38	0.11	0.00	0.26	3/13265	Object#work	68
    93.11%	53.58%	0.59	0.34	0.00	0.25	13265	*Array#each	
     	 	0.19	0.01	0.00	0.18	13254/13254	Enumerable#all?	97
     	 	
 
Точка роста сместилась внутри метода work к методу #each, но уже в другом месте.    
Теперь в оптимизации нуждается этот участок:  

      file_lines.each do |line|
        cols = line.split(',')
        users = users + [parse_user(line)] if cols[0] == 'user'
        sessions = sessions + [parse_session(line)] if cols[0] == 'session'
      end

### Ваша находка №2
Вторая находка мало отличалаь от первой.  
Данные не были оптимальны.   
Группировка снизила время обработки файла со 100_000 строк до 2.2 секунд.  
    
    RubyProf::FlatPrinter
    
    %self      total      self      wait     child     calls  name                           location
     35.57      2.698     1.102     0.000     1.596    15367  *Array#each                     
     11.44      0.983     0.355     0.000     0.628   168896   Array#map                      
      8.76      0.518     0.271     0.000     0.247    84645   <Class::Date>#parse            
      7.26      0.225     0.225     0.000     0.000   200001   String#split                   
      4.97      0.154     0.154     0.000     0.000    84646   Array#include?                 
      4.04      0.125     0.125     0.000     0.000   253449   String#encode                  
      3.50      0.259     0.108     0.000     0.150        1   JSON::Ext::Generator::GeneratorMethods::Hash#to_json 
      2.97      0.092     0.092     0.000     0.000   169290   Regexp#match                   
      2.75      0.195     0.085     0.000     0.110    84646   Object#parse_session           /home/slim1979/projects/study_projects/tn_rails_optimization/course1/rails-optimization-2-task1/task-1.rb:27
      2.33      0.095     0.072     0.000     0.023    30709   Array#sort                     
      1.74      0.054     0.054     0.000     0.000   233447   String#upcase                  
      1.74      0.054     0.054     0.000     0.000   107478   Hash#merge                     
      1.73      0.054     0.054     0.000     0.000    84645   String#gsub!                   
      1.55      0.048     0.048     0.000     0.000    84645   MatchData#begin                
      1.37      0.042     0.042     0.000     0.000    84645   Date#iso8601
    
    RubyProf::GraphHtmlPrinter
    
    100.00%	0.01%	0.35	0.00	0.00	0.35	1	[global]#	10
            0.35	0.00	0.00	0.35	1/1	Object#work	10
            0.00	0.00	0.00	0.00	1/1	<Object::Object>#[]	10
            0.35	0.00	0.00	0.35	1/1	[global]#	10
    99.99%	0.04%	0.35	0.00	0.00	0.35	1	Object#work	46
            0.19	0.00	0.00	0.19	7/7	Object#collect_stats_from_users	122
            0.05	0.00	0.00	0.05	1/1	Hash#each_key	55
            0.04	0.01	0.00	0.02	2/2041	Array#each	90
            0.03	0.01	0.00	0.01	1/1	JSON::Ext::Generator::GeneratorMethods::Hash#to_json	156
            0.02	0.00	0.00	0.02	2/2	Enumerable#group_by	50
            0.01	0.01	0.00	0.00	1/26509	String#split	50
            0.01	0.01	0.00	0.00	2/22310	Array#map	99
            0.00	0.00	0.00	0.00	1/1	<Class::IO>#read	50
            0.00	0.00	0.00	0.00	1/4057	Array#sort	99
            0.00	0.00	0.00	0.00	1/1	<Class::IO>#write	156
            0.00	0.00	0.00	0.00	1/1	Array#uniq	99
            0.00	0.00	0.00	0.00	2/2	Kernel#puts	47
            0.00	0.00	0.00	0.00	1/2029	Array#join	99
            0.00	0.00	0.00	0.00	3/2031	Array#count	85
            0.00	0.00	0.00	0.00	2028/2041	Enumerable#all?	
            0.02	0.01	0.00	0.01	2/2041	Enumerable#group_by	
            0.04	0.01	0.00	0.02	2/2041	Object#work	90
            0.05	0.01	0.00	0.03	2/2041	Hash#each_key	
            0.19	0.05	0.00	0.15	7/2041	Object#collect_stats_from_users	39
    86.09%	24.26%	0.30	0.08	0.00	0.21	2041	*Array#each	
            0.12	0.04	0.00	0.08	22308/22310	Array#map
            
            
Точка роста еще в методе #work, но здоровье у нее уже не то)

### Ваша находка №3
file_lines.each был повторно пересмотрен и переработан  

      file_lines.each_key do |key|
        file_lines[key].map do |value|
          array = key == 'user' ? users : sessions
          array.push(send "parse_#{key}", value.split(','))
        end
      end

Время обработки файла сократилось до 1.86 секунд.  

### Ваша находка №4
Профайлер показал смещение точки роста в метод #each в строке 99

            Профайлер RubyProf::Graph

            0.00	0.00	0.00	0.00	2028/2039	Enumerable#all?	
            0.02	0.01	0.00	0.01	2/2039	Enumerable#group_by	
            0.03	0.01	0.00	0.02	2/2039	Object#work	99
            0.18	0.04	0.00	0.14	7/2039	Object#collect_stats_from_users	37
    72.00%	18.17%	0.23	0.06	0.00	0.18	2039	*Array#each	
            0.11	0.04	0.00	0.07	22308/22312	Array#map

      ===== смещение точки роста ====
       
      sessions.each do |session|
        browser = session['browser']
        uniqueBrowsers += [browser] unless uniqueBrowsers.include? browser
      end

метод был изменен на 


      sessions.each do |session|
        browser = session['browser']
        uniqueBrowsers.push(browser)
      end
    
      uniqueBrowsers.uniq!
      

профилирование сместило акцент в сторону метода

    def collect_stats_from_users(report, users_objects, &block)
      users_objects.each do |user|
        user_key = "#{user.attributes['first_name']}" + ' ' + "#{user.attributes['last_name']}"
        report['usersStats'][user_key] ||= {}
        report['usersStats'][user_key] = report['usersStats'][user_key].merge(block.call(user))
      end
    end
    
    %self      total      self      wait     child     calls  name                           location
     19.51      1.398     0.480     0.000     0.919   168898   Array#map                      
     18.76      1.817     0.461     0.000     1.356    15365  *Array#each                     
     13.13      0.598     0.323     0.000     0.276    84645   <Class::Date>#parse            
      9.35      0.230     0.230     0.000     0.000   200001   String#split
 
       
      	 	0.18	0.00	0.00	0.18	7/7	Object#work	133
     58.91%	0.00%	0.18	0.00	0.00	0.18	7	Object#collect_stats_from_users	36
      	 	0.18	0.04	0.00	0.15	7/2039	Array#each	37
    
      	 	
     RubyProf::CallStackPrinter
     	
     Thread: 4064700, Fiber: 9696280 (100.00% ~ 21.811634497978957)
     100.00% (100.00%) [global]# [1 calls, 1 total]
     100.00% (100.00%) Object#work [1 calls, 1 total]
     54.10% (54.10%) Object#collect_stats_from_users [1 calls, 1 total]
     54.10% (100.00%) Array#each [1 calls, 5 total]
     44.84% (82.89%) Array#map [923448 calls, 923452 total]
     27.15% (60.55%) <Class::Date>#parse [846091 calls, 846091 total]
      	 	
### Ваша находка №5
Первым делом я решил изменить работу конкатенации.
Потом взялся за блок. Убрал его из аргументов, изменил вызов на yield. Это срезало еще 0.2 мс  
Профилировщик указал на то, что основная возня происходит в строке 135 в методе #map.
До это я собрал разнозненные вызовы в один

      collect_stats_from_users(report, users_objects) do |user|
        {
            'sessionsCount' => user.sessions.count,
            'totalTime' => user.sessions.map { |s| s['time'].to_i }.sum.to_s + ' min.',
            'longestSession' => user.sessions.map { |s| s['time'].to_i }.max.to_s + ' min.',
            'browsers' => user.sessions.map { |s| s['browser'].upcase }.sort.join(', '),
            'usedIE' => user.sessions.map { |s| s['browser'] }.any? { |b| b.upcase =~ /INTERNET EXPLORER/ },
            'alwaysUsedChrome' => user.sessions.map { |s| s['browser'] }.all? { |b| b.upcase =~ /CHROME/ },
            'dates' => user.sessions.map { |s| s['date'] }.sort.reverse
        }
      end

И теперь где-то внутри требуется оптимизация.
Сразу бросается в глаза то, что один и то же массив вызывается несколько раз и с ним происходи несколько однотипных действий:  
.to_i и .upcase

Сделано так

      collect_stats_from_users(report, users_objects) do |user|
        time_map      = user.sessions.map { |s| s['time'].to_i }
        browser_map   = user.sessions.map { |s| s['browser'].upcase }
        always_chrome = !(browser_map.group_by { |s| s[0] }.count > 1)
        used_ie       = browser_map.include? 'INTERNET EXPLORER'
        {
            'sessionsCount' => user.sessions.count,
            'totalTime' => "#{time_map.sum} min.",
            'longestSession' => "#{time_map.max} min.",
            'browsers' => browser_map.sort.join(', '),
            'usedIE' => used_ie,
            'alwaysUsedChrome' => always_chrome,
            'dates' => user.sessions.map { |s| s['date'] }.sort.reverse
        }

Пробный запуск на полном объеме данных дал 45 секунд.
Надо похудеть на треть для попадания в бюджет.
Идем к профйалерам.

### Ваша находка №5

     	 	3.77	2.82	0.00	0.95	1500000/1500005	Array#each	
     	 	5.57	2.56	0.00	3.00	3/1500005	Object#work	80
     	 	16.13	4.78	0.00	11.35	2/1500005	Hash#each_key	
    47.62%	19.01%	25.46	10.16	0.00	15.30	1500005	Array#map	
     	 	7.10	7.10	0.00	0.00	3250940/3250941	String#split	56
     	 	3.37	3.37	0.00	0.00	2750940/2750940	Object#parse_s	56
     	 	2.10	2.10	0.00	0.00	5501880/5501880	String#upcase	88
     	 	1.43	1.27	0.00	0.16	500000/500000	Class#new	96
     	 	0.44	0.44	0.00	0.00	500000/500000	Object#parse_u	56
     	 	0.44	0.44	0.00	0.00	3250940/3250940	Array#push	56

Это ведет меня к методу, который я ранее уже рефакторил.

      file_lines.each_key do |key|
        # binding.pry
        file_lines[key].map do |value|
          array = key == 'u' ? users : sessions
          array.push(send "parse_#{key}", value.split(','))
        end
      end
      
Метод #each_key используется только здесь. Следовательно, тут и наша точка роста.  
Что тут происходит? Профилировщик указывает на большое количество вызовов #map.  
Немного подумав, я вспомнил про метод Array#fill и решил изменить код на вот этот:  

      file_lines.each_key do |key|
        array = key == 'u' ? users : sessions
        array.fill( file_lines[key].map{ |value| send "parse_#{key}", value.split(',') } )
      end

Здесь мы один раз создаем массив и один раз его заливаем в нужный нам массив.
Что скажут тесты?

При выключенном GC тесты проходят за ~ 17.6  
При включенном ~ 39.6  


## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с 25 дней до 40 секунд и  почти уложиться в заданный бюджет.

Наглядно увидел, как можно писать неоптимальный код.  
Понял, что есть пробелы в знании руби и производительности методов.  
Надо более широко применять бенчмарки и профайлеры.

## Защита от регрессии производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы был написан тест, который тестирует время исполнения.
